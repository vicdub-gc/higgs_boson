{"cells":[{"cell_type":"markdown","source":"# Project 1 : Higgs Boson classification","metadata":{"cell_id":"fcc988eb9be9407cac0ee83ccc0191a8","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"<hr style=\"clear:both\">\nThis notebook was made for the CS-433 class (Machine Learning) at EPFL.\n    \n**Authors:** \\\n[Tristan Carruzzo](https://people.epfl.ch/tristan.carruzzo)\\\n[Victor Dubien](https://people.epfl.ch/victor.dubien)\\\n[Anne-Val√©rie Preto](https://people.epfl.ch/anne-valerie.preto)\n<hr style=\"clear:both\">","metadata":{"cell_id":"991e260ea82f427ebc02b59312ab44ee","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Contents","metadata":{"cell_id":"a08e077d1d1c459696d5c6df324847ac","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sn\nfrom implementations import *\nimport math as ma\nimport matplotlib.pyplot as plt\nimport random\nrandom.seed(16)","metadata":{"cell_id":"a1b6916e7bae434bb951b6642083ddfb","source_hash":"7d37f938","execution_start":1667219991285,"execution_millis":683,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# 1. Pre-processing","metadata":{"cell_id":"dd2f22916c464fb1a081e0ea291c6562","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## 1.1. Data import","metadata":{"cell_id":"238ce19e376446be9f8ab1850f10fac7","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"y_train, X_train, ID_train = load_csv_data('train.csv', sub_sample=False)","metadata":{"cell_id":"edbd7f17680f452382b177e7259a227f","source_hash":"e892d5e","execution_start":1667219991972,"execution_millis":5616,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"y_test, X_test, ID_test = load_csv_data('test.csv', sub_sample=False)","metadata":{"cell_id":"132eb489384145debcf9931dcbf13616","source_hash":"ca16259c","execution_start":1667220010772,"execution_millis":12471,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"y_train[y_train==-1] = 0","metadata":{"cell_id":"9e52837ddeb645f19945c60414ca22c2","source_hash":"b24c3cdc","execution_start":1667220026322,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 1.2. Data separation according to column 22 \"PRI_jet_num\"","metadata":{"cell_id":"99f02084a72b4b59afa0d2d243563f66","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#splitting the data\nX_train_0 = X_train[(X_train[:,22] == 0),:]\nX_train_1 = X_train[(X_train[:,22] == 1),:]\nX_train_2 = X_train[(X_train[:,22] == 2),:]\nX_train_3 = X_train[(X_train[:,22] == 3),:]\nX_test_0 = X_test[(X_test[:,22] == 0),:]\nX_test_1 = X_test[(X_test[:,22] == 1),:]\nX_test_2 = X_test[(X_test[:,22] == 2),:]\nX_test_3 = X_test[(X_test[:,22] == 3),:]\ny_train_0 = y_train[X_train[:,22] == 0]\ny_train_1 = y_train[X_train[:,22] == 1]\ny_train_2 = y_train[X_train[:,22] == 2]\ny_train_3 = y_train[X_train[:,22] == 3]\nID_train_0 = ID_train[X_train[:,22] == 0]\nID_train_1 = ID_train[X_train[:,22] == 1]\nID_train_2 = ID_train[X_train[:,22] == 2]\nID_train_3 = ID_train[X_train[:,22] == 3]\nID_test_0 = ID_test[X_test[:,22] == 0]\nID_test_1 = ID_test[X_test[:,22] == 1]\nID_test_2 = ID_test[X_test[:,22] == 2]\nID_test_3 = ID_test[X_test[:,22] == 3]","metadata":{"cell_id":"7fa39acfe7334c8e896b5e33c68f1d50","source_hash":"195263dd","execution_start":1667220030295,"execution_millis":178,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 1.3. NaN handling","metadata":{"cell_id":"90ec1a558f6c4c3eba36c09e58fc01cb","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#detection of columns which are full of -999 or full of 0\ncol_0 = [22] \ncol_1 = [22]\ncol_2 = [22]\ncol_3 = [22]\nfor col in range(0,30):\n    if (np.all(X_train_0[:,col]==-999) == True) or (np.all(X_train_0[:,col]==0) == True):\n        col_0.append(col)\n    if (np.all(X_train_1[:,col]==-999) == True) or (np.all(X_train_1[:,col]==0) == True):\n        col_1.append(col)\n    if (np.all(X_train_2[:,col]==-999) == True) or (np.all(X_train_2[:,col]==0) == True):\n        col_2.append(col)\n    if (np.all(X_train_3[:,col]==-999) == True) or (np.all(X_train_3[:,col]==0) == True):\n        col_3.append(col)\nprint(col_0,\"\\n\",col_1,\"\\n\",col_2,\"\\n\",col_3) ","metadata":{"cell_id":"30cc49fdc3694f27bffec147a8d22b62","source_hash":"4c140c6f","execution_start":1667220034866,"execution_millis":63,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"[22, 4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29] \n [22, 4, 5, 6, 12, 26, 27, 28] \n [22] \n [22]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#Deleting the said columns\nX_train_0=np.delete(X_train_0,col_0,axis=1)\nX_test_0=np.delete(X_test_0,col_0,axis=1)\n\nX_train_1=np.delete(X_train_1,col_1,axis=1)\nX_test_1=np.delete(X_test_1,col_1,axis=1)\n\nX_train_2=np.delete(X_train_2,col_2,axis=1)\nX_test_2=np.delete(X_test_2,col_2,axis=1)\n\nX_train_3=np.delete(X_train_3,col_3,axis=1)\nX_test_3=np.delete(X_test_3,col_3,axis=1)","metadata":{"cell_id":"e465ec4933da430299ec96ed918d5599","source_hash":"e4cbaf8d","execution_start":1667220038398,"execution_millis":76,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Columns 0 of each of the 8 arrays still contains some \"-999\", we replace them with NaNs in order to deal with them. They will be replaced with the mean of the column","metadata":{"cell_id":"0532fa059d114ac2b992739f2e754617","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"X_train_nan_0 = np.where(X_train_0[:,:] == -999, np.nan, X_train_0[:,:])\nX_train_nan_1 = np.where(X_train_1[:,:] == -999, np.nan, X_train_1[:,:])\nX_train_nan_2 = np.where(X_train_2[:,:] == -999, np.nan, X_train_2[:,:])\nX_train_nan_3 = np.where(X_train_3[:,:] == -999, np.nan, X_train_3[:,:]) \nnanmeantrain0 = np.nanmean(X_train_nan_0[:,0])\nnanmeantrain1 = np.nanmean(X_train_nan_1[:,0])\nnanmeantrain2 = np.nanmean(X_train_nan_2[:,0])\nnanmeantrain3 = np.nanmean(X_train_nan_3[:,0])\nX_train_0[:,0] = np.where(X_train_0[:,0] == -999, nanmeantrain0, X_train_0[:,0])\nX_train_1[:,0] = np.where(X_train_1[:,0] == -999, nanmeantrain1, X_train_1[:,0])\nX_train_2[:,0] = np.where(X_train_2[:,0] == -999, nanmeantrain2, X_train_2[:,0])\nX_train_3[:,0] = np.where(X_train_3[:,0] == -999, nanmeantrain3, X_train_3[:,0])\nX_test_0[:,0] = np.where(X_test_0[:,0] == -999, nanmeantrain0, X_test_0[:,0])\nX_test_1[:,0] = np.where(X_test_1[:,0] == -999, nanmeantrain1, X_test_1[:,0])\nX_test_2[:,0] = np.where(X_test_2[:,0] == -999, nanmeantrain2, X_test_2[:,0])\nX_test_3[:,0] = np.where(X_test_3[:,0] == -999, nanmeantrain3, X_test_3[:,0])","metadata":{"cell_id":"a7f3427ea08748bd894c4faa82019f2b","source_hash":"44580dba","execution_start":1667220042300,"execution_millis":29,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#keeping copies of the arrays for the third part of the code before modifying them\nX_train_0_bis = X_train_0.copy()\nX_train_1_bis = X_train_1.copy()\nX_train_2_bis = X_train_2.copy()\nX_train_3_bis = X_train_3.copy()\nX_test_0_bis = X_test_0.copy()\nX_test_1_bis = X_test_1.copy()\nX_test_2_bis = X_test_2.copy()\nX_test_3_bis = X_test_3.copy()","metadata":{"cell_id":"4e253cb99eae42748a9ea78ea433e45e","source_hash":"43802070","execution_start":1667220046283,"execution_millis":38,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 1.4. Feature expansion","metadata":{"cell_id":"b4483109910a48d9874588935e83076a","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# degree for each set\nexpansion_degree_0 = 4\nexpansion_degree_1 = 7 \nexpansion_degree_2 = 4 \nexpansion_degree_3 = 5 ","metadata":{"cell_id":"9ce259f8420a4155a7e40b85f3fd882d","source_hash":"4853bc53","execution_start":1667219981623,"execution_millis":1,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#creation of the new arrays\nnew_X_train_0 = np.zeros((X_train_0.shape[0], X_train_0.shape[1]*expansion_degree_0))\nnew_X_train_1 = np.zeros((X_train_1.shape[0], X_train_1.shape[1]*expansion_degree_1))\nnew_X_train_2 = np.zeros((X_train_2.shape[0], X_train_2.shape[1]*expansion_degree_2))\nnew_X_train_3 = np.zeros((X_train_3.shape[0], X_train_3.shape[1]*expansion_degree_3))\nnew_X_test_0 = np.zeros((X_test_0.shape[0], X_test_0.shape[1]*expansion_degree_0))\nnew_X_test_1 = np.zeros((X_test_1.shape[0], X_test_1.shape[1]*expansion_degree_1))\nnew_X_test_2 = np.zeros((X_test_2.shape[0], X_test_2.shape[1]*expansion_degree_2))\nnew_X_test_3 = np.zeros((X_test_3.shape[0], X_test_3.shape[1]*expansion_degree_3))\n\n#replacing the original values in the first columns\nnew_X_train_0[:,0:X_train_0.shape[1]] = X_train_0\nnew_X_train_1[:,0:X_train_1.shape[1]] = X_train_1\nnew_X_train_2[:,0:X_train_2.shape[1]] = X_train_2\nnew_X_train_3[:,0:X_train_3.shape[1]] = X_train_3\nnew_X_test_0[:,0:X_test_0.shape[1]] = X_test_0\nnew_X_test_1[:,0:X_test_1.shape[1]] = X_test_1\nnew_X_test_2[:,0:X_test_2.shape[1]] = X_test_2\nnew_X_test_3[:,0:X_test_3.shape[1]] = X_test_3\n                      \n#placing the values in the array\ncount=0\nfor i in range(X_train_0.shape[1]):\n    for j in range(2, expansion_degree_0+1):\n        new_X_train_0[:,count+X_train_0.shape[1]] = X_train_0[:,i]**j\n        new_X_test_0[:, count+X_test_0.shape[1]] = X_test_0[:,i]**j\n        count += 1\n        \ncount=0\nfor i in range(X_train_1.shape[1]):\n    for j in range(2, expansion_degree_1+1):\n        new_X_train_1[:,count+X_train_1.shape[1]] = X_train_1[:,i]**j\n        new_X_test_1[:, count+X_test_1.shape[1]] = X_test_1[:,i]**j\n        count += 1\n\ncount=0\nfor i in range(X_train_2.shape[1]):\n    for j in range(2, expansion_degree_2+1):\n        new_X_train_2[:,count+X_train_2.shape[1]] = X_train_2[:,i]**j\n        new_X_test_2[:, count+X_test_2.shape[1]] = X_test_2[:,i]**j\n        count += 1\n        \ncount=0\nfor i in range(X_train_3.shape[1]):\n    for j in range(2, expansion_degree_3+1):\n        new_X_train_3[:,count+X_train_3.shape[1]] = X_train_3[:,i]**j\n        new_X_test_3[:, count+X_test_3.shape[1]] = X_test_3[:,i]**j\n        count += 1\n        \n        \nX_train_0 = new_X_train_0\nX_train_1 = new_X_train_1\nX_train_2 = new_X_train_2\nX_train_3 = new_X_train_3\nX_test_0 = new_X_test_0\nX_test_1 = new_X_test_1\nX_test_2 = new_X_test_2\nX_test_3 = new_X_test_3","metadata":{"cell_id":"99415fa4064440c4a6e8b0cbe0973ee0","source_hash":"5cfc53a1","execution_start":1667219981624,"execution_millis":3844,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## 1.5. Normalisation","metadata":{"cell_id":"902f42197d77478cbe2efab26bd5f999","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"mean_0 = np.mean(X_train_0,axis=0)\nstd_0 = np.std(X_train_0,axis=0)\nX_train_0 = normalize(X_train_0,mean_0,std_0)\nX_test_0 = normalize(X_test_0,mean_0,std_0)\n\nmean_1 = np.mean(X_train_1,axis=0)\nstd_1 = np.std(X_train_1,axis=0)\nX_train_1 = normalize(X_train_1,mean_1,std_1)\nX_test_1 = normalize(X_test_1,mean_1,std_1)\n\nmean_2 = np.mean(X_train_2,axis=0)\nstd_2 = np.std(X_train_2,axis=0)\nX_train_2 = normalize(X_train_2,mean_2,std_2)\nX_test_2 = normalize(X_test_2,mean_2,std_2)\n\nmean_3 = np.mean(X_train_3,axis=0)\nstd_3 = np.std(X_train_3,axis=0)\nX_train_3 = normalize(X_train_3,mean_3,std_3)\nX_test_3 = normalize(X_test_3,mean_3,std_3)","metadata":{"cell_id":"8e17d382ac764ed195ec1b4ae7364c11","source_hash":"33fe5dfe","execution_start":1667219985474,"execution_millis":565,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## 1.6. K-Fold for cross validation","metadata":{"cell_id":"0a1779c1d75944a8a1d9a88a17cc9006","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#splitting the train arrays in equal parts\nk_fold_0=11\nfold_x_0,fold_y_0 = k_fold_data(X_train_0,y_train_0,k_fold_0)\n\nk_fold_1=8\nfold_x_1,fold_y_1 = k_fold_data(X_train_1,y_train_1,k_fold_1)\n\nk_fold_2=7\nfold_x_2,fold_y_2 = k_fold_data(X_train_2,y_train_2,k_fold_2)\n\nk_fold_3=6\nfold_x_3,fold_y_3 = k_fold_data(X_train_3,y_train_3,k_fold_3)\n\n#rearranging\nxs_0 = np.zeros((k_fold_0,fold_x_0.shape[1]*(k_fold_0-1),X_train_0.shape[1])) \nys_0 = np.zeros((fold_x_0.shape[1]*(k_fold_0-1),k_fold_0))\nfor i in range(k_fold_0):\n    ys_0[:,i] = np.delete(fold_y_0,i,axis=1).reshape((fold_x_0.shape[1]*(k_fold_0-1),),order='F') \n    xs_0[i,:,:] = np.delete(fold_x_0,i,axis=0).reshape((fold_x_0.shape[1]*(k_fold_0-1),X_train_0.shape[1])) \n\nxs_1 = np.zeros((k_fold_1,fold_x_1.shape[1]*(k_fold_1-1),X_train_1.shape[1])) \nys_1 = np.zeros((fold_x_1.shape[1]*(k_fold_1-1),k_fold_1))\nfor i in range(k_fold_1):\n    ys_1[:,i] = np.delete(fold_y_1,i,axis=1).reshape((fold_x_1.shape[1]*(k_fold_1-1),),order='F')\n    xs_1[i,:,:] = np.delete(fold_x_1,i,axis=0).reshape((fold_x_1.shape[1]*(k_fold_1-1),X_train_1.shape[1])) \n\nxs_2 = np.zeros((k_fold_2,fold_x_2.shape[1]*(k_fold_2-1),X_train_2.shape[1])) \nys_2 = np.zeros((fold_x_2.shape[1]*(k_fold_2-1),k_fold_2))\nfor i in range(k_fold_2):\n    ys_2[:,i] = np.delete(fold_y_2,i,axis=1).reshape((fold_x_2.shape[1]*(k_fold_2-1),),order='F')\n    xs_2[i,:,:] = np.delete(fold_x_2,i,axis=0).reshape((fold_x_2.shape[1]*(k_fold_2-1),X_train_2.shape[1])) \n\nxs_3 = np.zeros((k_fold_3,fold_x_3.shape[1]*(k_fold_3-1),X_train_3.shape[1])) \nys_3 = np.zeros((fold_x_3.shape[1]*(k_fold_3-1),k_fold_3))\nfor i in range(k_fold_3):\n    ys_3[:,i] = np.delete(fold_y_3,i,axis=1).reshape((fold_x_3.shape[1]*(k_fold_3-1),),order='F')\n    xs_3[i,:,:] = np.delete(fold_x_3,i,axis=0).reshape((fold_x_3.shape[1]*(k_fold_3-1),X_train_3.shape[1]))","metadata":{"cell_id":"45d8b361f38a4d58a11f7d4d83ef8128","source_hash":"a53c304d","execution_start":1667219986055,"execution_millis":1296,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# 2. Base Models","metadata":{"cell_id":"ced31f794f11479c8a50a23f843426dd","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Mean squared error gradient descent, mean squared error stochastic gradient descent, least squares and ridge regression","metadata":{"cell_id":"96b4c9c89d4f4f429a8659f3f4556876","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### On dataset 0","metadata":{"cell_id":"c3ca945ec8db4af2a1ae6abf0673db8f","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"w_s=[]\nlosses=[]\ninitial_w=np.full((X_train_0.shape[1],1), 1e-16) \nmax_iters=100\naccs=[]\nprecs=[]\nrecs=[]\nF1s=[]\nbatch_size = 1 \nlambda_ = 1e-3\ngamma = 1e-2\n\nfor i in range(k_fold_0):\n    ys_i = ys_0[:,i].reshape((fold_x_0.shape[1]*(k_fold_0-1),1))\n    xs_i = xs_0[i,:,:]\n\n    #1) mean_squared_error_gd\n    #gamma = 0.1 \n    #w,loss = least_squares_GD(ys_i, xs_i, initial_w, max_iters, gamma)\n\n    #2) mean_squared_error_sgd\n    #gamma = 1e-3 \n    #w,loss = least_squares_SGD(ys_i, xs_i,initial_w, max_iters, gamma)\n        \n    #3) least_squares\n    #w,loss = least_squares(ys_i, xs_i)\n\n    #4) ridge_regression\n    #lambda =  0.001 | Accuracy moyenne : 0.7595 | D = 4\n    w,loss = ridge_regression(ys_i, xs_i, lambda_)\n    \n    #5) logistic regression\n    #w,loss = logistic_regression(y_train_0, X_train_0, initial_w, max_iters, gamma)\n\n    #6) reg_logistic_regression\n    #w,loss = reg_logistic_regression(y_train_0, X_train_0, lambda_ ,initial_w, max_iters, gamma) \n\n        \n    losses.append(loss)\n    \n    val_x_i = fold_x_0[i,:,:]\n        \n    val_y_i = fold_y_0[:,i].reshape((fold_x_0.shape[1],1)) \n\n    y_pred=val_x_i.dot(w)\n    y_pred = compute_sigmoid(y_pred)\n    y_pred[y_pred>0.5] = 1\n    y_pred[y_pred<=0.5] = 0\n\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n    for pred in range(len(y_pred)):\n        if (y_pred[pred] == 1 and val_y_i[pred] == 1):\n            TP+=1\n        elif (y_pred[pred] == 1 and val_y_i[pred] == 0):\n            FP+=1\n        elif (y_pred[pred] == 0 and val_y_i[pred] == 1):\n            FN+=1\n        else :\n            TN+=1\n    acc = (TP+TN)/len(y_pred)\n    prec = TP/(TP+FP)\n    rec = TP/(TP+FN)\n    F1score = 2*prec*rec/(prec+rec)\n\n    if acc > 0.75 :\n        w_s.append(w)\n\n    accs.append(acc)\n    precs.append(prec)\n    recs.append(recs)\n    F1s.append(F1score)\n    conf_matrix = np.array([[TP, FP], [FN, TN]])\n        \nw_s = np.asarray(w_s)\nprint(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.75 :\",w_s.shape[0])\nprint(accs)\nw_avg_0 = np.mean(w_s,axis = 0)\nprint(\"Norme de w_0 :\",np.linalg.norm(w_avg_0),\"\\n\\n\")","metadata":{"cell_id":"579fedb52c1744c7aed9a3eb8f98c04c","source_hash":"20799957","execution_start":1667219987359,"execution_millis":2159,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[{"output_type":"error","ename":"KernelInterrupted","evalue":"Execution interrupted by the Jupyter kernel.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."]}],"execution_count":14},{"cell_type":"markdown","source":"### On dataset 1","metadata":{"tags":[],"cell_id":"2450f61290f34095bb51ae9f9e3b92b5","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"w_s=[]\nlosses=[]\ninitial_w=np.full((X_train_1.shape[1],1), 1e-16) \nmax_iters=100\naccs=[]\nprecs=[]\nrecs=[]\nF1s=[]\nbatch_size = 1 \nlambda_ = 1e-16\ngamma = 1e-2\n\nfor i in range(k_fold_1):\n    ys_i = ys_1[:,i].reshape((fold_x_1.shape[1]*(k_fold_1-1),1))\n    xs_i = xs_1[i,:,:]\n\n    #1) mean_squared_error_gd\n    #gamma = 1e-5\n    #w,loss = least_squares_GD(ys_i, xs_i, initial_w, max_iters, gamma)\n\n    #2) mean_squared_error_sgd\n    #gamma = 1e-3\n    #w,loss = least_squares_SGD(ys_i, xs_i,initial_w, max_iters, gamma)\n        \n    #3) least_squares\n    #w,loss = least_squares(ys_i, xs_i)\n\n    #4) ridge_regression\n    #lambda =  1e-10 | Accuracy moyenne : 0.72605 | D = 4\n    w,loss = ridge_regression(ys_i, xs_i, lambda_)\n    \n    #5) logistic regression\n    #w,loss = logistic_regression(y_train_0, X_train_0, initial_w, max_iters, gamma)\n\n    #6) reg_logistic_regression\n    #w,loss = reg_logistic_regression(y_train_0, X_train_0, lambda_ ,initial_w, max_iters, gamma)\n\n        \n    losses.append(loss)\n\n    val_x_i = fold_x_1[i,:,:]\n        \n    val_y_i = fold_y_1[:,i].reshape((fold_x_1.shape[1],1)) \n\n    y_pred=val_x_i.dot(w)\n    y_pred = compute_sigmoid(y_pred)\n    y_pred[y_pred>0.5] = 1\n    y_pred[y_pred<=0.5] = 0\n\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n    for pred in range(len(y_pred)):\n        if (y_pred[pred] == 1 and val_y_i[pred] == 1):\n            TP+=1\n        elif (y_pred[pred] == 1 and val_y_i[pred] == 0):\n            FP+=1\n        elif (y_pred[pred] == 0 and val_y_i[pred] == 1):\n            FN+=1\n        else :\n            TN+=1\n    acc = (TP+TN)/len(y_pred)\n    prec = TP/(TP+FP)\n    rec = TP/(TP+FN)\n    F1score = 2*prec*rec/(prec+rec)\n\n    if acc > 0.72 :\n        w_s.append(w)\n\n    accs.append(acc)\n    precs.append(prec)\n    recs.append(recs)\n    F1s.append(F1score)\n    conf_matrix = np.array([[TP, FP], [FN, TN]])\n        \nw_s = np.asarray(w_s)\nprint(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.72 :\",w_s.shape[0])\nprint(accs)\nw_avg_1 = np.mean(w_s,axis = 0)\nprint(\"Norme de w_1 :\",np.linalg.norm(w_avg_1),\"\\n\\n\")","metadata":{"cell_id":"a8e022f2408f40eeb90211345a412675","source_hash":"f38866fb","execution_start":1667219923310,"execution_millis":2297,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"lambda =  1e-16 | Accuracy moyenne : 0.7359950479727638 | Acc>0.72 : 7\n[0.7365108841431961, 0.7368203858454555, 0.7339317032910347, 0.7425977509542969, 0.7439389249974209, 0.7408439079748272, 0.7137109254100897, 0.7396059011657897]\nNorme de w_1 : 101065.50376765091 \n\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### On dataset 2","metadata":{"cell_id":"c240bc4e321341bbbaba7095dc0d1836","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"w_s=[]\nlosses=[]\ninitial_w=np.full((X_train_2.shape[1],1), 1e-16) \nmax_iters=100\naccs=[]\nprecs=[]\nrecs=[]\nF1s=[]\nbatch_size = 1 \nlambda_ = 1e-10\ngamma = 1e-2\n\nfor i in range(k_fold_2):\n    ys_i = ys_2[:,i].reshape((fold_x_2.shape[1]*(k_fold_2-1),1))\n    xs_i = xs_2[i,:,:]\n\n    #1) mean_squared_error_gd\n    #gamma = 0.1\n    #w,loss = least_squares_GD(ys_i, xs_i, initial_w, max_iters, gamma)\n\n    #2) mean_squared_error_sgd\n    #gamma = 1e-3 \n    #w,loss = least_squares_SGD(ys_i, xs_i,initial_w, max_iters, gamma)\n        \n    #3) least_squares\n    #w,loss = least_squares(ys_i, xs_i)\n\n    #4) ridge_regression\n    #lambda =  1e-16 | Accuracy moyenne : 0.72605 | D = 4\n    w,loss = ridge_regression(ys_i, xs_i, lambda_)\n    \n    #5) logistic regression\n    #w,loss = logistic_regression(y_train_0, X_train_0, initial_w, max_iters, gamma)\n\n    #6) reg_logistic_regression\n    #w,loss = reg_logistic_regression(y_train_0, X_train_0, lambda_ ,initial_w, max_iters, gamma)\n\n        \n    losses.append(loss)\n\n    val_x_i = fold_x_2[i,:,:]\n        \n    val_y_i = fold_y_2[:,i].reshape((fold_x_2.shape[1],1)) \n\n    y_pred=val_x_i.dot(w)\n    y_pred = compute_sigmoid(y_pred)\n    y_pred[y_pred>0.5] = 1\n    y_pred[y_pred<=0.5] = 0\n\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n    for pred in range(len(y_pred)):\n        if (y_pred[pred] == 1 and val_y_i[pred] == 1):\n            TP+=1\n        elif (y_pred[pred] == 1 and val_y_i[pred] == 0):\n            FP+=1\n        elif (y_pred[pred] == 0 and val_y_i[pred] == 1):\n            FN+=1\n        else :\n            TN+=1\n    acc = (TP+TN)/len(y_pred)\n    prec = TP/(TP+FP)\n    rec = TP/(TP+FN)\n    F1score = 2*prec*rec/(prec+rec)\n\n    if acc > 0.72 :\n        w_s.append(w)\n\n    accs.append(acc)\n    precs.append(prec)\n    recs.append(recs)\n    F1s.append(F1score)\n    conf_matrix = np.array([[TP, FP], [FN, TN]])\n        \nw_s = np.asarray(w_s)\nprint(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.72 :\",w_s.shape[0])\nprint(accs)\nw_avg_2 = np.mean(w_s,axis = 0)\nprint(\"Norme de w_2 :\",np.linalg.norm(w_avg_2),\"\\n\\n\")","metadata":{"cell_id":"490f3b0672bc4c60b5033e87814525da","source_hash":"ccf68c73","execution_start":1667219925617,"execution_millis":1723,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"lambda =  1e-10 | Accuracy moyenne : 0.806129538101193 | Acc>0.72 : 7\n[0.8086702792830346, 0.8072808114492149, 0.8081144921495067, 0.8089481728497985, 0.8078365985827428, 0.795331388078366, 0.806725024315687]\nNorme de w_2 : 24.644642300643167 \n\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### On dataset 3","metadata":{"cell_id":"e7f1ff85bd344d9dbbb175936a91419b","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"w_s=[]\nlosses=[]\ninitial_w=np.full((X_train_3.shape[1],1), 1e-16) \nmax_iters=100\naccs=[]\nprecs=[]\nrecs=[]\nF1s=[]\nbatch_size = 1 \nlambda_ = 1e-16\ngamma = 1e-2\n\nfor i in range(k_fold_3):\n    ys_i = ys_3[:,i].reshape((fold_x_3.shape[1]*(k_fold_3-1),1))\n    xs_i = xs_3[i,:,:]\n\n    #1) mean_squared_error_gd\n    #gamma = 1e-5 \n    #w,loss = least_squares_GD(ys_i, xs_i, initial_w, max_iters, gamma)\n\n    #2) mean_squared_error_sgd\n    #gamma = 1e-3 \n    #w,loss = least_squares_SGD(ys_i, xs_i,initial_w, max_iters, gamma)\n        \n    #3) least_squares\n    #w,loss = least_squares(ys_i, xs_i)\n\n    #4) ridge_regression\n    #lambda =  1e-16 | Accuracy moyenne : 0.72605 | D = 4\n    w,loss = ridge_regression(ys_i, xs_i, lambda_)\n    \n    #5) logistic regression\n    #w,loss = logistic_regression(y_train_0, X_train_0, initial_w, max_iters, gamma)\n\n    #6) reg_logistic_regression\n    #w,loss = reg_logistic_regression(y_train_0, X_train_0, lambda_ ,initial_w, max_iters, gamma)\n\n        \n    losses.append(loss)\n\n    val_x_i = fold_x_3[i,:,:]\n        \n    val_y_i = fold_y_3[:,i].reshape((fold_x_3.shape[1],1)) \n\n    y_pred=val_x_i.dot(w)\n    y_pred = compute_sigmoid(y_pred)\n    y_pred[y_pred>0.5] = 1\n    y_pred[y_pred<=0.5] = 0\n\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n    for pred in range(len(y_pred)):\n        if (y_pred[pred] == 1 and val_y_i[pred] == 1):\n            TP+=1\n        elif (y_pred[pred] == 1 and val_y_i[pred] == 0):\n            FP+=1\n        elif (y_pred[pred] == 0 and val_y_i[pred] == 1):\n            FN+=1\n        else :\n            TN+=1\n    acc = (TP+TN)/len(y_pred)\n    prec = TP/(TP+FP)\n    rec = TP/(TP+FN)\n    F1score = 2*prec*rec/(prec+rec)\n\n    if acc > 0.7 :\n        w_s.append(w)\n\n    accs.append(acc)\n    precs.append(prec)\n    recs.append(recs)\n    F1s.append(F1score)\n    conf_matrix = np.array([[TP, FP], [FN, TN]])\n        \nw_s = np.asarray(w_s)\nprint(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.7 :\",w_s.shape[0])\nprint(accs)\nw_avg_3 = np.mean(w_s,axis = 0)\nprint(\"Norme de w_3 :\",np.linalg.norm(w_avg_3),\"\\n\\n\")","metadata":{"cell_id":"70450fa6cce543beb4c90bdfa65607ce","source_hash":"92f9fa84","execution_start":1667219927103,"execution_millis":985,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"lambda =  1e-16 | Accuracy moyenne : 0.7095289658906334 | Acc>0.7 : 5\n[0.7030319436924742, 0.7149431510557661, 0.7165674066053059, 0.7144017325392529, 0.6997834325933947, 0.7084461288576069]\nNorme de w_3 : 163.16556669010563 \n\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## 2.2 Predictions","metadata":{"cell_id":"0d7b4de8f5834da4be55cd571e20c1ef","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"y_test_0 = np.dot(X_test_0,w_avg_0)\ny_test_0 = compute_sigmoid(y_test_0)\ny_test_0[y_test_0>=0.5] = 1 \ny_test_0[y_test_0<0.5] = -1 \n\ny_test_1 = np.dot(X_test_1,w_avg_1)\ny_test_1 = compute_sigmoid(y_test_1)\ny_test_1[y_test_1>=0.5] = 1 \ny_test_1[y_test_1<0.5] = -1 \n\ny_test_2 = np.dot(X_test_2,w_avg_2)\ny_test_2 = compute_sigmoid(y_test_2)\ny_test_2[y_test_2>=0.5] = 1 \ny_test_2[y_test_2<0.5] = -1 \n\ny_test_3 = np.dot(X_test_3,w_avg_3)\ny_test_3 = compute_sigmoid(y_test_3)\ny_test_3[y_test_3>=0.5] = 1 \ny_test_3[y_test_3<0.5] = -1 ","metadata":{"cell_id":"90498aacd6154dbcb7a7ccf86a05c486","source_hash":"deb73b97","execution_start":1667219928092,"execution_millis":95,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## 2.3. Putting everything together and creating the csv","metadata":{"cell_id":"604116ef7e41430d989267205dbdcfc7","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"ID = np.concatenate((ID_test_0,ID_test_1,ID_test_2,ID_test_3),axis=0)\nID.shape = [568238,1]\ny_test = np.concatenate((y_test_0,y_test_1,y_test_2,y_test_3),axis=0) \ny_to_sort = np.concatenate((ID,y_test),axis=1)\ny_sorted = y_to_sort[y_to_sort[:, 0].argsort()]\ny_to_submit = y_sorted[:,1]\n#create_csv_submission(ID_test, y_to_submit, \"method_1.csv\")","metadata":{"cell_id":"6aa6795eacc3422b8ec1fcbd91935cc9","source_hash":"8359e8f5","execution_start":1667219928191,"execution_millis":101,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# 3. Advanced Models","metadata":{"cell_id":"c4354f7a67454cc4a89d947af2e3ea51","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"# Regularised logistic regression with binary cross-entropy loss","metadata":{"cell_id":"262a4bea9b4041f7be33fd97f1a3e825","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"X_train_0 = X_train_0_bis\nX_train_1 = X_train_1_bis\nX_train_2 = X_train_2_bis\nX_train_3 = X_train_3_bis\nX_test_0 = X_test_0_bis\nX_test_1 = X_test_1_bis\nX_test_2 = X_test_2_bis\nX_test_3 = X_test_3_bis","metadata":{"cell_id":"036f03185c824ac7abbfc6f50767bdb1","source_hash":"27cd992","execution_start":1667220060850,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# degree\nexpansion_degree_0 = 5\nexpansion_degree_1 = 9 #√† changer\nexpansion_degree_2 = 9 #4\nexpansion_degree_3 = 9\n\n#creation of the new arrays\nnew_X_train_0 = np.zeros((X_train_0.shape[0], X_train_0.shape[1]*expansion_degree_0))\nnew_X_train_1 = np.zeros((X_train_1.shape[0], X_train_1.shape[1]*expansion_degree_1))\nnew_X_train_2 = np.zeros((X_train_2.shape[0], X_train_2.shape[1]*expansion_degree_2))\nnew_X_train_3 = np.zeros((X_train_3.shape[0], X_train_3.shape[1]*expansion_degree_3))\nnew_X_test_0 = np.zeros((X_test_0.shape[0], X_test_0.shape[1]*expansion_degree_0))\nnew_X_test_1 = np.zeros((X_test_1.shape[0], X_test_1.shape[1]*expansion_degree_1))\nnew_X_test_2 = np.zeros((X_test_2.shape[0], X_test_2.shape[1]*expansion_degree_2))\nnew_X_test_3 = np.zeros((X_test_3.shape[0], X_test_3.shape[1]*expansion_degree_3))\n\n#replacing the original values in the first columns\nnew_X_train_0[:,0:X_train_0.shape[1]] = X_train_0\nnew_X_train_1[:,0:X_train_1.shape[1]] = X_train_1\nnew_X_train_2[:,0:X_train_2.shape[1]] = X_train_2\nnew_X_train_3[:,0:X_train_3.shape[1]] = X_train_3\nnew_X_test_0[:,0:X_test_0.shape[1]] = X_test_0\nnew_X_test_1[:,0:X_test_1.shape[1]] = X_test_1\nnew_X_test_2[:,0:X_test_2.shape[1]] = X_test_2\nnew_X_test_3[:,0:X_test_3.shape[1]] = X_test_3\n                      \n#placing the values in the array\ncount=0\nfor i in range(X_train_0.shape[1]):\n    for j in range(2, expansion_degree_0+1):\n        new_X_train_0[:,count+X_train_0.shape[1]] = X_train_0[:,i]**j\n        new_X_test_0[:, count+X_test_0.shape[1]] = X_test_0[:,i]**j\n        count += 1\n        \ncount=0\nfor i in range(X_train_1.shape[1]):\n    for j in range(2, expansion_degree_1+1):\n        new_X_train_1[:,count+X_train_1.shape[1]] = X_train_1[:,i]**j\n        new_X_test_1[:, count+X_test_1.shape[1]] = X_test_1[:,i]**j\n        count += 1\n\ncount=0\nfor i in range(X_train_2.shape[1]):\n    for j in range(2, expansion_degree_2+1):\n        new_X_train_2[:,count+X_train_2.shape[1]] = X_train_2[:,i]**j\n        new_X_test_2[:, count+X_test_2.shape[1]] = X_test_2[:,i]**j\n        count += 1\n        \ncount=0\nfor i in range(X_train_3.shape[1]):\n    for j in range(2, expansion_degree_3+1):\n        new_X_train_3[:,count+X_train_3.shape[1]] = X_train_3[:,i]**j\n        new_X_test_3[:, count+X_test_3.shape[1]] = X_test_3[:,i]**j\n        count += 1\n        \n        \nX_train_0 = new_X_train_0\nX_train_1 = new_X_train_1\nX_train_2 = new_X_train_2\nX_train_3 = new_X_train_3\nX_test_0 = new_X_test_0\nX_test_1 = new_X_test_1\nX_test_2 = new_X_test_2\nX_test_3 = new_X_test_3\nX_train_0.shape","metadata":{"cell_id":"1c7721a6da8441c8b6ec97828b935c32","source_hash":"e774e5c","execution_start":1667220063733,"execution_millis":8643,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"(99913, 90)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"X_train_0, X_val_0, y_train_0, y_val_0 = separation_validation(X_train_0, y_train_0, 0.8)\nX_train_1, X_val_1, y_train_1, y_val_1 = separation_validation(X_train_1, y_train_1, 0.8)\nX_train_2, X_val_2, y_train_2, y_val_2 = separation_validation(X_train_2, y_train_2, 0.8)\nX_train_3, X_val_3, y_train_3, y_val_3 = separation_validation(X_train_3, y_train_3, 0.8)","metadata":{"cell_id":"9fb6a7097e714e03b47f1e7122b5992b","source_hash":"450dcf35","execution_start":1667220078658,"execution_millis":108,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":13},{"cell_type":"code","source":"mean_0 = np.mean(X_train_0, axis=0)\nmean_1 = np.mean(X_train_1, axis=0)\nmean_2 = np.mean(X_train_2, axis=0)\nmean_3 = np.mean(X_train_3, axis=0)\nstd_0 = np.std(X_train_0, axis=0)\nstd_1 = np.std(X_train_1, axis=0)\nstd_2 = np.std(X_train_2, axis=0)\nstd_3 = np.std(X_train_3, axis=0)\nX_train_0 = normalize(X_train_0, mean_0, std_0)\nX_train_1 = normalize(X_train_1, mean_1, std_1)\nX_train_2 = normalize(X_train_2, mean_2, std_2)\nX_train_3 = normalize(X_train_3, mean_3, std_3)\nX_val_0 = normalize(X_val_0, mean_0, std_0)\nX_val_1 = normalize(X_val_1, mean_1, std_1)\nX_val_2 = normalize(X_val_2, mean_2, std_2)\nX_val_3 = normalize(X_val_3, mean_3, std_3)\nX_test_0 = normalize(X_test_0, mean_0, std_0)\nX_test_1 = normalize(X_test_1, mean_1, std_1)\nX_test_2 = normalize(X_test_2, mean_2, std_2)\nX_test_3 = normalize(X_test_3, mean_3, std_3)","metadata":{"cell_id":"06837c58128a465089dbf149c55376d2","source_hash":"f75d2840","execution_start":1667220081721,"execution_millis":756,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"max_iters_0 = 403\nlr0 = 0.2\nloss_freq = 40\ndecay = 0.995\nlambda_0 = 0.001\n\nw_0, b_0, logger_0 = train_reg_logistic_regression(X_train_0, y_train_0, max_iters_0, lr0, loss_freq, decay, lambda_0)","metadata":{"cell_id":"1169db02baf040acb720fda1a2693bf7","source_hash":"b3502898","execution_start":1667220085370,"execution_millis":84314,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Step size = 80\n/root/work/implementations.py:36: RuntimeWarning: overflow encountered in exp\n  sigmoid = 1/(1+np.exp(-x))\nLoss at iter 0: 2.49802\nAccuracy at iter 0:  0.5816214187413987\nLearning rate : 0.20000\nLoss at iter 40: 0.63817\nAccuracy at iter 40:  0.746340547979482\nLearning rate : 0.17294\nLoss at iter 80: 0.50933\nAccuracy at iter 80:  0.8131114725384712\nLearning rate : 0.14152\nLoss at iter 120: 0.48766\nAccuracy at iter 120:  0.8216439384461404\nLearning rate : 0.11581\nLoss at iter 160: 0.47787\nAccuracy at iter 160:  0.8250594269986238\nLearning rate : 0.09477\nLoss at iter 200: 0.47198\nAccuracy at iter 200:  0.8271362442136869\nLearning rate : 0.07755\nLoss at iter 240: 0.46795\nAccuracy at iter 240:  0.8284248717627924\nLearning rate : 0.06346\nLoss at iter 280: 0.46504\nAccuracy at iter 280:  0.8290754410108845\nLearning rate : 0.05193\nLoss at iter 320: 0.46287\nAccuracy at iter 320:  0.8298636306768422\nLearning rate : 0.04250\nLoss at iter 360: 0.46122\nAccuracy at iter 360:  0.830038783935944\nLearning rate : 0.03478\nLoss at iter 400: 0.45994\nAccuracy at iter 400:  0.8302639809833604\nLearning rate : 0.02846\n\nFinal loss: 0.45988\n\nFinal accuracy: 0.83030\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"y_pred_0 = logistic_output(X_val_0, w_0, b_0)\ny_pred_0[y_pred_0>0.5] = 1\ny_pred_0[y_pred_0<=0.5] = 0\nTP = 0\nFP = 0\nTN = 0\nFN = 0\nfor pred in range(len(y_val_0)):\n    if (y_pred_0[pred] == 1) & (y_val_0[pred] == 1):\n        TP+=1\n    elif (y_pred_0[pred] == 1) & (y_val_0[pred] == 0):\n        FP+=1\n    elif (y_pred_0[pred] == 0) & (y_val_0[pred] == 1):\n        FN+=1\n    else :\n        TN+=1\nacc = (TP+TN)/len(y_pred_0)\nprec = TP/(TP+FP)\nrec = TP/(TP+FN)\nF1score = 2*prec*rec/(prec+rec)\nprint(\"Validation accuracy : \", acc*100, \"%, precision = \", prec, \"recall = \", rec, \"F1-Score = \", F1score)","metadata":{"cell_id":"66e4a05a6ff2456488b872a0d1b7757c","source_hash":"438b5e62","execution_start":1667220169693,"execution_millis":96,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Validation accuracy :  82.89546114197067 %, precision =  0.7128125805620005 recall =  0.5454724797790491 F1-Score =  0.6180151989271345\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"y_test_0 = logistic_output(X_test_0, w_0, b_0)\ny_test_0[y_test_0>0.5] = 1\ny_test_0[y_test_0<=0.5] = -1","metadata":{"tags":[],"cell_id":"6c22ba72140249f591b260e47689300d","source_hash":"e338d2a8","execution_start":1667220178554,"execution_millis":13,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"max_iters_1 = 403\nlr1 = 0.8\nloss_freq = 40\ndecay = 0.9999\nlambda_1 = 0.0001\n\nw_1, b_1, logger_1 = train_reg_logistic_regression(X_train_1, y_train_1, max_iters_1, lr1, loss_freq, decay, lambda_1)","metadata":{"cell_id":"830d6acb55c1484f8757e0ff8a384d4f","source_hash":"2045c125","execution_start":1667220183242,"execution_millis":107937,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Step size = 80\nLoss at iter 0: 4.13413\nAccuracy at iter 0:  0.544047714999597\nLearning rate : 0.80000\nLoss at iter 40: 0.59721\nAccuracy at iter 40:  0.7327476424599016\nLearning rate : 0.79768\nLoss at iter 80: 0.53650\nAccuracy at iter 80:  0.7524784395905537\nLearning rate : 0.79450\nLoss at iter 120: 0.51939\nAccuracy at iter 120:  0.7599903280406223\nLearning rate : 0.79133\nLoss at iter 160: 0.51024\nAccuracy at iter 160:  0.7633110340936569\nLearning rate : 0.78817\nLoss at iter 200: 0.50411\nAccuracy at iter 200:  0.7662287418392842\nLearning rate : 0.78502\nLoss at iter 240: 0.49911\nAccuracy at iter 240:  0.7688724107358749\nLearning rate : 0.78189\nLoss at iter 280: 0.49532\nAccuracy at iter 280:  0.7706778431530588\nLearning rate : 0.77877\nLoss at iter 320: 0.49231\nAccuracy at iter 320:  0.7719190779398727\nLearning rate : 0.77566\nLoss at iter 360: 0.48985\nAccuracy at iter 360:  0.773128072862094\nLearning rate : 0.77256\nLoss at iter 400: 0.48773\nAccuracy at iter 400:  0.774320947852019\nLearning rate : 0.76948\n\nFinal loss: 0.48763\n\nFinal accuracy: 0.77434\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"y_pred_1 = logistic_output(X_val_1, w_1, b_1)\ny_pred_1[y_pred_1>0.5] = 1\ny_pred_1[y_pred_1<=0.5] = 0\nTP = 0\nFP = 0\nTN = 0\nFN = 0\nfor pred in range(len(y_val_1)):\n    if (y_pred_1[pred] == 1) & (y_val_1[pred] == 1):\n        TP+=1\n    elif (y_pred_1[pred] == 1) & (y_val_1[pred] == 0):\n        FP+=1\n    elif (y_pred_1[pred] == 0) & (y_val_1[pred] == 1):\n        FN+=1\n    else :\n        TN+=1\nacc = (TP+TN)/len(y_pred_1)\nprec = TP/(TP+FP)\nrec = TP/(TP+FN)\nF1score = 2*prec*rec/(prec+rec)\nprint(\"Validation accuracy : \", acc*100, \"%, precision = \", prec, \"recall = \", rec, \"F1-Score = \", F1score)","metadata":{"cell_id":"51c3c48ead5d4afabbc5a3c04582ee8e","source_hash":"51e34fb9","execution_start":1667220290504,"execution_millis":784,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Validation accuracy :  77.59365529692437 %, precision =  0.7151834583417799 recall =  0.6302250803858521 F1-Score =  0.6700218402810749\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"y_test_1 = logistic_output(X_test_1, w_1, b_1)\ny_test_1[y_test_1>0.5] = 1\ny_test_1[y_test_1<=0.5] = -1","metadata":{"cell_id":"212ece43c3ff4fa0b32cb19e0453c122","source_hash":"7ccd7351","execution_start":1667220296507,"execution_millis":11,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":20},{"cell_type":"code","source":"max_iters_2 = 403\nlr2 = 0.55\nloss_freq = 40\ndecay = 0.999\nlambda_2 = 0.0001\n\nw_2, b_2, logger_2 = train_reg_logistic_regression(X_train_2, y_train_2, max_iters_2, lr2, loss_freq, decay, lambda_2)","metadata":{"cell_id":"472559e571424eed9f67bd9b6ebb111d","source_hash":"ca7371b8","execution_start":1667220341254,"execution_millis":87637,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Step size = 80\nLoss at iter 0: 4.56593\nAccuracy at iter 0:  0.513187603900454\nLearning rate : 0.55000\nLoss at iter 40: 0.75417\nAccuracy at iter 40:  0.7036945140560256\nLearning rate : 0.53427\nLoss at iter 80: 0.59318\nAccuracy at iter 80:  0.7416073245167853\nLearning rate : 0.51331\nLoss at iter 120: 0.54950\nAccuracy at iter 120:  0.7566930501451505\nLearning rate : 0.49317\nLoss at iter 160: 0.53045\nAccuracy at iter 160:  0.7634667394486763\nLearning rate : 0.47383\nLoss at iter 200: 0.51855\nAccuracy at iter 200:  0.7679329082202317\nLearning rate : 0.45524\nLoss at iter 240: 0.51053\nAccuracy at iter 240:  0.7707862938242811\nLearning rate : 0.43738\nLoss at iter 280: 0.50473\nAccuracy at iter 280:  0.7737637396719848\nLearning rate : 0.42022\nLoss at iter 320: 0.50017\nAccuracy at iter 320:  0.7755998312780686\nLearning rate : 0.40374\nLoss at iter 360: 0.49641\nAccuracy at iter 360:  0.7778081036151155\nLearning rate : 0.38790\nLoss at iter 400: 0.49318\nAccuracy at iter 400:  0.7791479542465821\nLearning rate : 0.37268\n\nFinal loss: 0.49303\n\nFinal accuracy: 0.77920\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"y_pred_2 = logistic_output(X_val_2, w_2, b_2)\ny_pred_2[y_pred_2>0.5] = 1\ny_pred_2[y_pred_2<=0.5] = 0\nTP = 0\nFP = 0\nTN = 0\nFN = 0\nfor pred in range(len(y_val_2)):\n    if (y_pred_2[pred] == 1) & (y_val_2[pred] == 1):\n        TP+=1\n    elif (y_pred_2[pred] == 1) & (y_val_2[pred] == 0):\n        FP+=1\n    elif (y_pred_2[pred] == 0) & (y_val_2[pred] == 1):\n        FN+=1\n    else :\n        TN+=1\nacc = (TP+TN)/len(y_pred_2)\nprec = TP/(TP+FP)\nrec = TP/(TP+FN)\nF1score = 2*prec*rec/(prec+rec)\nprint(\"Validation accuracy : \", acc*100, \"%, precision = \", prec, \"recall = \", rec, \"F1-Score = \", F1score)","metadata":{"cell_id":"b7fbf7b790174581829c0a9a48140422","source_hash":"d30b7629","execution_start":1667220428894,"execution_millis":182,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Validation accuracy :  78.19571258435887 %, precision =  0.7869008974603781 recall =  0.7921953094963475 F1-Score =  0.7895392278953923\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"y_test_2 = logistic_output(X_test_2, w_2, b_2)\ny_test_2[y_test_2>0.5] = 1\ny_test_2[y_test_2<=0.5] = -1","metadata":{"cell_id":"495ff0ac2d4144968c8934bfbb13e046","source_hash":"2f0848d6","execution_start":1667220428991,"execution_millis":85,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":23},{"cell_type":"code","source":"max_iters_3 = 403\nlr3 = 0.8\nloss_freq = 40\ndecay = 0.9999\nlambda_3 = 0.001\n\nw_3, b_3, logger_3 = train_reg_logistic_regression(X_train_3, y_train_3, max_iters_3, lr3, loss_freq, decay, lambda_3)","metadata":{"cell_id":"37c21546be6943b087f0c8e51dfccdd2","source_hash":"e8992fbc","execution_start":1667220429081,"execution_millis":43682,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Step size = 80\nLoss at iter 0: 4.73206\nAccuracy at iter 0:  0.5045400710619818\nLearning rate : 0.80000\nLoss at iter 40: 0.83146\nAccuracy at iter 40:  0.7114657943714399\nLearning rate : 0.79768\nLoss at iter 80: 0.70568\nAccuracy at iter 80:  0.7345327392702047\nLearning rate : 0.79450\nLoss at iter 120: 0.64704\nAccuracy at iter 120:  0.7477863628672946\nLearning rate : 0.79133\nLoss at iter 160: 0.60926\nAccuracy at iter 160:  0.7568665049912583\nLearning rate : 0.78817\nLoss at iter 200: 0.58425\nAccuracy at iter 200:  0.7637471095820879\nLearning rate : 0.78502\nLoss at iter 240: 0.56590\nAccuracy at iter 240:  0.7669054198860752\nLearning rate : 0.78189\nLoss at iter 280: 0.55162\nAccuracy at iter 280:  0.7687665670294964\nLearning rate : 0.77877\nLoss at iter 320: 0.54059\nAccuracy at iter 320:  0.7704585189780611\nLearning rate : 0.77566\nLoss at iter 360: 0.53243\nAccuracy at iter 360:  0.7725452597146241\nLearning rate : 0.77256\nLoss at iter 400: 0.52520\nAccuracy at iter 400:  0.7735604308837629\nLearning rate : 0.76948\n\nFinal loss: 0.52486\n\nFinal accuracy: 0.77362\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"y_pred_3 = logistic_output(X_val_3, w_3, b_3)\ny_pred_3[y_pred_3>0.5] = 1\ny_pred_3[y_pred_3<=0.5] = 0\nTP = 0\nFP = 0\nTN = 0\nFN = 0\nfor pred in range(len(y_val_3)):\n    if (y_pred_3[pred] == 1) & (y_val_3[pred] == 1):\n        TP+=1\n    elif (y_pred_3[pred] == 1) & (y_val_3[pred] == 0):\n        FP+=1\n    elif (y_pred_3[pred] == 0) & (y_val_3[pred] == 1):\n        FN+=1\n    else :\n        TN+=1\nacc = (TP+TN)/len(y_pred_3)\nprec = TP/(TP+FP)\nrec = TP/(TP+FN)\nF1score = 2*prec*rec/(prec+rec)\nprint(\"Validation accuracy : \", acc*100, \"%, precision = \", prec, \"recall = \", rec, \"F1-Score = \", F1score)","metadata":{"cell_id":"29c163db55dc45328b2827971168ce1b","source_hash":"f61b99d4","execution_start":1667220472520,"execution_millis":246,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Validation accuracy :  77.64493570945183 %, precision =  0.7061611374407583 recall =  0.44510828976848393 F1-Score =  0.5460375629867155\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"y_test_3 = logistic_output(X_test_3, w_3, b_3)\ny_test_3[y_test_3>0.5] = 1\ny_test_3[y_test_3<=0.5] = -1","metadata":{"cell_id":"1a7505694652435c952df016aedbd1d5","source_hash":"af7a74e7","execution_start":1667220472593,"execution_millis":84,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":26},{"cell_type":"code","source":"ID = np.concatenate((ID_test_0,ID_test_1,ID_test_2,ID_test_3),axis=0)\nID.shape = [568238,1]\ny_test = np.concatenate((y_test_0,y_test_1,y_test_2,y_test_3),axis=0) \ny_test.shape = [568238,1]\ny_to_sort = np.concatenate((ID,y_test),axis=1)\ny_sorted = y_to_sort[y_to_sort[:, 0].argsort()]\ny_to_submit = y_sorted[:,1]","metadata":{"cell_id":"e2a821b3f4c7496ea281152f8f9f8ea8","source_hash":"9b8264a4","execution_start":1667220472681,"execution_millis":105,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":27},{"cell_type":"code","source":"count =0\nfor i in range(len(y_to_submit)) :\n    if y_to_submit[i] == 1:\n        count+=1\nprint(count*100/len(y_to_submit),\"% de valeur √† 1\") #34,27% dans y_train","metadata":{"cell_id":"e4e17d75717a429c845eb664846c19e0","source_hash":"13e959c2","execution_start":1667220472797,"execution_millis":89,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"29.830810329474623 % de valeur √† 1\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"create_csv_submission(ID_test, y_to_submit, \"test_final2.csv\")","metadata":{"cell_id":"b502f185a8d1420a86f5685f76b482fd","source_hash":"5905bbf9","execution_start":1667220518662,"execution_millis":1119,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":29},{"cell_type":"code","source":"","metadata":{"cell_id":"b2d1aa8741c94b2b8572362893a70082","source_hash":"b623e53d","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a9cac0cd-fc8e-4c76-a346-a5de9c0344c9' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python","version":"3.9.7","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"6aabc53c89e34b61a16ae94ccf9c1cce","deepnote_execution_queue":[]}}